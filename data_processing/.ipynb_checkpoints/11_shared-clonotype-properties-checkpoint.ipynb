{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDR3 entropy in shared and unshared clonotypes\n",
    "\n",
    "Starting with unique cross-subject clonotype datasets, computes per-position entropy for CDR3s in unshared or shared (found in at least 6 of 10 samples) clonotypes.\n",
    "\n",
    "The following Python packages are required:\n",
    "  * numpy\n",
    "  * pandas\n",
    "\n",
    "and can be installed by running `pip install numpy pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from collections import Counter\n",
    "import os\n",
    "import subprocess as sp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sequences\n",
    "\n",
    "The raw dataset (unique cross-subject clonotypes) is too large to be included in this Github repo. Instead, a compressed archive containing all of the required data can be downloaded [**HERE**](http://burtonlab.s3.amazonaws.com/GRP_github_data/dedup_10-subject_pools.tar.gz). Decompressing the archive in the `./data` directory will allow the following code blocks to run without modification.\n",
    "\n",
    "***NOTE:*** *The required data files are relatively large (~30GB in total), so ensure adequate storage space is available before downloading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(seq_files):\n",
    "    all_seqs = {}\n",
    "    for seq_type in seq_files.keys():\n",
    "        seq_file = seq_files[seq_type]\n",
    "        seqs = {'shared': {i: [] for i in range(7, 15)},\n",
    "                'unshared': {i: [] for i in range(7, 15)}}\n",
    "        with open(seq_file) as f:\n",
    "            for line in f:\n",
    "                sline = line.strip().split()\n",
    "                if not sline:\n",
    "                    continue\n",
    "                try:\n",
    "                    c = int(sline[0])\n",
    "                    if c == 1:\n",
    "                        s = 'unshared'\n",
    "                    elif c in range(6, 11):\n",
    "                        s = 'shared'\n",
    "                    else:\n",
    "                        continue\n",
    "                    aa = sline[3]\n",
    "                    l = len(aa)\n",
    "                    if l not in range(7, 15):\n",
    "                        continue\n",
    "                    seqs[s][l].append(aa)\n",
    "                except IndexError:\n",
    "                    continue\n",
    "        all_seqs[seq_type] = seqs\n",
    "    # downselect sequences so that shared and unshared pools are the same size\n",
    "    selected_seqs = {t: {'shared': {}, 'unshared': {}} for t in all_seqs.keys()}\n",
    "    for seq_type in ['observed', 'subject-specific synthetic']:\n",
    "        for length in range(7, 15):\n",
    "            num_seqs = min([len(all_seqs[seq_type][t][length]) for t in ['shared', 'unshared']])\n",
    "            for shared_type in ['shared', 'unshared']:\n",
    "                s = all_seqs[seq_type][shared_type][length]\n",
    "                if len(s) > num_seqs:\n",
    "                    s = np.random.choice(s, size=num_seqs, replace=False)\n",
    "                selected_seqs[seq_type][shared_type][length] = s\n",
    "    return all_seqs, selected_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'observed': './data/dedup_10-subject_pools/10-subject_dedup_pool_with-counts.txt',\n",
    "         'subject-specific synthetic': './data/dedup_10-subject_pools/10-sample_dedup_pool_synthetic_subject-specific-models_with-counts.txt'}\n",
    "\n",
    "all_seqs, seq_dict = get_sequences(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute shared/unshared CDR3 entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropies(seq_dict, seq_type):\n",
    "    edata = []\n",
    "    for s in seq_dict.keys():\n",
    "        for l in seq_dict[s].keys():\n",
    "            seqs = seq_dict[s][l]\n",
    "            for residues in list(zip(*seqs))[3:-3]:\n",
    "                e = entropy(residues)\n",
    "                edata.append({'sample': '{} ({})'.format(seq_type, s), 'seq_type': seq_type,\n",
    "                              'Shannon entropy': e, 'CDR3 length': l, 'shared': s})\n",
    "    return edata\n",
    "\n",
    "\n",
    "def entropy(residues):\n",
    "    n_residues = len(residues)\n",
    "    if n_residues <= 1:\n",
    "        return 0.\n",
    "    counts = np.asarray(Counter(residues).values(), dtype=np.float64)\n",
    "    probs = counts[np.nonzero(counts)] / n_residues\n",
    "    n_classes = len(probs)\n",
    "    if n_classes <= 1:\n",
    "        return 0.\n",
    "    return - np.sum(probs * np.log(probs)) / np.log(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_data = []\n",
    "print('Getting sequences...')\n",
    "for seq_type in seq_dict.keys():\n",
    "    print(seq_type)\n",
    "    entropies = calculate_entropies(seq_dict[seq_type], seq_type)\n",
    "    entropy_data += entropies\n",
    "\n",
    "entropy_df = pd.DataFrame(entropy_data)\n",
    "entropy_df.to_csv('./data/per-position_shannon_entropies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared CDR3 sequence properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_seqs = []\n",
    "for n in range(6, 11):\n",
    "    shared_seqs += seqs[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
